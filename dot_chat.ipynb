{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Govt_dummy/DoT_Finance_Compendium.pdf\n",
      "chunk[0]\n",
      "DISCLAIMER \n",
      " \n",
      "  \n",
      "   This compendium has been published and all possible \n",
      "necessary care has been taken to make the material error-free. \n",
      "While every effort has been made to avoid any mistake or \n",
      "omission, neither IFD nor printer would be liable in any manner \n",
      "for any mistake/omission in this publication or for any action \n",
      "proposed/ taken or omitted to be proposed/ taken or advice \n",
      "rendered or accepted on the basis of this work. This \n",
      "compendium is prepared for use as a ready reckoner only and \n",
      "the reader is advised to exercise discretion and further consult \n",
      "the original OMs/instructions/guidelines. We look forward to \n",
      "your valuable feedback/ suggestions/corrections in this \n",
      "compilation.  \n",
      " \n",
      " \n",
      "First Edition     : 2016 \n",
      "Second Edition: 2017 \n",
      "Third Edition   : 2019 \n",
      "Fourth Edition  : 2023\n",
      "--------------------------------------------------\n",
      "chunk[1]\n",
      "DOT FINANCE COMPENDIUM-2023 \n",
      "  Updated upto February, 2023\n",
      "(IMPORTANT ORDERS/INSTRUCTIONS\n",
      "ON FINANCIAL MATTERS)\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import glob \n",
    "import os \n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1000, \n",
    "    chunk_overlap = 50\n",
    ")\n",
    "for file in glob.glob(os.path.join(\"Govt_dummy\", \"*.pdf\")):\n",
    "    print(f'Processing: {file}')\n",
    "    documents = PyPDFLoader(file).load()\n",
    "    all_splits = text_splitter.split_documents(documents)\n",
    "    # Printing 2 chunks \n",
    "    for i, chunk in enumerate(all_splits[:2]): \n",
    "        print(f'chunk[{i}]\\n{chunk.page_content}\\n' + '-'*50)\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating vector-store from scratch.\n"
     ]
    }
   ],
   "source": [
    "model_embed_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings': True}\n",
    "hf = HuggingFaceEmbeddings(model_name = model_embed_name, \\\n",
    "                           model_kwargs = model_kwargs, \\\n",
    "                           encode_kwargs = encode_kwargs)\n",
    "vector_db_dir = \"./DoT_Gov\"\n",
    "if os.path.exists(vector_db_dir):\n",
    "    vectorstore = Chroma(embedding_function = hf, persist_directory = vector_db_dir)\n",
    "else:\n",
    "    print('Creating vector-store from scratch.')\n",
    "    vectorstore = Chroma.from_documents(documents = all_splits, \\\n",
    "                                        embedding = hf, \n",
    "                                        persist_directory = vector_db_dir)\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='You are an AI assistant specializing in summarizing information from government documents.Always base your answers strictly on the provided context: K. Rajaraman said, \\'I am happy to learn that the fourth edition of the Finance Compendium is being published by IFD.\\'..If the answer is not found in the context or in your knowledge base, simply say, \"I don\\'t know.Do not make up or assume any information.', additional_kwargs={}, response_metadata={}), HumanMessage(content='What message has K. Rajaraman provided?', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"\"\"You are an AI assistant specializing in summarizing information from government documents.\"\"\" +\n",
    "                \"\"\"Always base your answers strictly on the provided context: {context}.\"\"\" +\n",
    "                \"\"\"If the answer is not found in the context or in your knowledge base, simply say, \"I don't know.\"\"\" + \n",
    "                \"\"\"Do not make up or assume any information.\"\"\"),\n",
    "        (\"user\", \"{query}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "prompt.invoke({\"context\": \"K. Rajaraman said, 'I am happy to learn that the fourth edition of the Finance Compendium is being published by IFD.'.\",\n",
    "               \"query\": \"What message has K. Rajaraman provided?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key = \"NA\"\n",
    "openai_api_base = \"http://localhost:8000/v1\"\n",
    "model_name = \"qwen2.5-7b-instruct-q4_0.gguf\"\n",
    "model = ChatOpenAI(\n",
    "    api_key = openai_api_key,\n",
    "    base_url = openai_api_base,\n",
    "    model_name = model_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model | StrOutputParser\n",
    "chain.invoke({\"context\": \"I like to have sex, said K. Rajaraman with coconut chuteny he added.\",\n",
    "               \"query\": \"What message has K. Rajaraman provided?\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
